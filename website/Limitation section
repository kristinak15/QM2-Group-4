Limitations of GM corn data set: Some of the limitations of the data and this exploration are that only certain states were available in the GM corn dataset meaning that the scope of the data is limited. This also affected the regression model, which becomes more unstable as more x-variables are added, but the length of the dataset is not extended. Nevertheless, the states included are the biggest agricultural producers in the United States, so the results are valuable.
 
Limitations of panel regression: Another crucial factor is that time series data was used, which means we had to normalise for the effect of time. Agricultural GDP, despite being more specific than normal GDP,  is an aggregate measure, meaning that a lot of factors affect it such as prices, exports, rural populations, which reduces the accuracy of the panel regression model. Agricultural employment may not be the best variable since agriculture is highly automated. Therefore the model may not be as robust as expected. The Wu-Hausman test should have been used to have empirical evidence for the chosen panel regression model. Limited knowledge and expertise in panel data analysis may have caused further errors in the methodology.
​
Limitations of Google Trend: As the data was in an Index Base 100 format, the data was not usable to know the actual number of online searches and discussions. The data was also not representative of the sentiment of the people and rather gave an idea of when the search peaks happened. Sentiment analysis was therefore executed through Twitter data. More generally, Google Trend is not a source which encompasses the entirety of public opinion, and therefore can't define the general public opinion. It is a tool for insights, and it gives a statistical overview, but only an overview, of public interactivity with a topic.

Limitations of the Twitter data: We were very limited by the API itself first of all, and by the latency at which we started to collect Twitter Data. As we were only allowed to gather 100 Tweets, which covered a period of one week, we had to run the API again three times, one during each new week, in order to reach 300 Tweets, as the analysis started on the 15th of December. This sample is extremely small and therefore cannot be seen as representative of either Twitter in general, or public opinion. To compensate, we used a former research which had previously compiled 1,500,000 Tweets to draw better conclusions and rely on more accurate data. Another fundamental sampling limitation is that with a topic as polarising and controversial as GMOs, people unhappy with the status quo or with stronger and more urgent views are more likely to tweet more compared to those who are impartial or uninterested, recalling that in Hallman’s survey of public perceptions (2013) 66% had never had a conversation about GMOs with anyone. Therefore the twittersphere in not representative of wider public opinion but perhaps a more extreme subset of it. The sample could also be limited by inequitable access to internet or technology, which although seems ubiquitous is important to remember in studies of online engagement that might exclude certain socioeconomic strata.
​
Limitations of the Natural Language Processing: The NLP was limited in the way it functioned as it did not take the general context of the Tweets in consideration. This resulted in a compilation of interesting words, but some could have expressed both a positive or negative sentiment. The TextBlob analysis, which was supposed to take consideration of context also gave surprising results, which almost opposed the results of the NLP. As Tweets on GMO were sometimes incomplete, sometimes non-logical, the results of the TextBlob analysis needs to be read with caution.
