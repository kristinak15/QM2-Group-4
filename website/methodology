Economic variables

Data collection and organisation

The y-variable chosen is Agricultural GDP and the x-variable is GM corn acreage. The other x-variables (corn yield, agricultural exports and employment in agriculture) were later added in order to improve the regression model since Agricultural GDP is affected by a variety of factors. All data for was collected by state to make a comparison, but also because it would give a more in depth look at GM crop usage and its effects. In order to get a greater breadth of data and analyse macroeconomic effects, the timeframe from 2005 to 2019 was used for each state. Due to the lack of data and time, other GM crops like cotton and soybeans were excluded from the analysis. In addition, 13 states were only available for GM corn area, whilst others were grouped under 'Other States', which were also excluded from the analysis.

The data for GM corn acreage, agricultural GDP, yield, exports was compiled from US Department of Agriculture (USDA) website and employment from Bureau of Labor Statistics (BLS) from separate CSV files, uploaded to Github and cleaned using pandas in Google Colab to make one dataframe. Since the GM corn acreage was given in percentage form, data for for total corn area planted was used to calculate the actual GM corn acreage values in acres. 

In order to create the geojson map, the shapefile for United States was downloaded from the Census Government website and used for the visual representation of the data and to reflect on the location of states that have a higher agricultural output and reliance on GM crops. 

Visualisations and panel regression analysis

The initial exploratory and descriptive data analysis was carried out using pandas, matplotlib, numpy and seaborn libraries. For the panel regression analysis, the linearmodels library was used. The panel linear regression was chosen as it analyses two-dimensional data (both longitudinal and cross sectional) (Introduction to the Fundamentals of Panel Data - Aptech, 2020). Since the data is a timeseries, with several panel units, which can be firms, countries or states like in our case, this was the most appropriate regression model. 

The equation for panel regression usually takes this form (Torres-Reyna, 2007):
 Y_it=β_1 X_it+α_i+u_it

Where:
	α_i (i=1....n) is the unknown intercept for each entity (n entity-specific intercepts
	Y_it is the dependent variable where i = entity and t = time, Agricultural GDP 
	X_it represents one independent variable such as the GM corn acreage, yield, employment or exports
	β_1is the coefficient for the independent variable 
	u_itis the error term 

Panel regression model uses two estimators: the fixed effects (FE), random effects (RE), where the suitability is determined using Durbin-Wu-Hausman test (Glen, n.d.). In linearmodels, the fixed effect estimation (PanelOLS) estimates the coefficients for the regression model (Models for Panel Data — linearmodels 4.5 documentation, 2021). It uses entity_effects function, which means the group means are fixed and not random, they can be used together with time_effects that normalises for the effect of time. The other models include random effect estimation (RandomEffects), between estimation (BetweenOLS) and Pooled Model estimation (PooledOLS), which does not include any effects and is the same as a multiple linear regression. All model results are derived in the analysis, but the most relevant ones were found to be the FE estimators since we are only interested in analyzing variables that vary over time (Torres-Reyna, 2007) and that account for the effect of time such as the PanelOLS with time_effects and PanelOLS with time as one of the variables. Therefore, these are the focus of the analysis. 

It is important to consider the several assumption for the data that should be tested if a regression analysis is to be carried out in order to avoid bias in the data. 
The standard assumptions for multiple linear regression are (Testing the assumptions of linear regression, 2021): 
	1. Linear relationships between y-variable and x-variables, which can be seen using a scatterplot.
	2. Multivariate normality: normal distribution of residuals, which is the distance between the data point and the regression line.  
	3. Homoscedasticity: the constant variance of errors
	4. No multicollinearity: independent variables are not highly correlated, which can be checked using multivariate correlation matrix.
	5. No autocorrelation using Durbin Watson test

However, having researched panel regression, it was unclear whether the exact same assumptions hold and no methods could be found to test for homoscedasticity 
or residuals in Python. Thus, it is assumed that these hold true. The linear relationships were analysed by looking at the scatterplots and multicollinearity using seaborn pairplot, and Durbin Watson test carried out showing a result at 1.914, which is between 1.5 ad 2.5 showing that the model is not autocorrelated.

For the geojson map, the geopandas and bookeh libraries were used. The shapefile was merged with the dataframe from the regression analysis and applied for the interactive map.


Public Opinion 
The aim of considering public opinion was to provide a statistical overview of how public opinion evolved throughout the development of genetically modified crop in the United-States. Is public opinion correlated with GMO production ? The term production will hereafter refers to the percentage of GM planted across the United-States. Has discussions online increased proportionally as more GM crops were implemented ? And how to qualify such discussions ?

In order to answer these questions, datasets were used from the USDA and Google Trend. The Google Trend data was directly collected from the Google Trend website. Google Trend informs on how users discuss a topic and on how to map levels of discussions geographically. The keyword selected was "GMO", and such term was defined as a "topic" and not as a "research term" in order to compile all searches associated with the topic of GMO rather than to compile all searches using only the three characters word. Google Trend therefore ensured that all terms referring to the topic of GMO, such as "genetically-modified crops", "bio-engineered food", "CRISPR plants" for example, were included in the data. 

The data points generated represented trends in searches on GMO in the United-States between 2007 and 2019. It is important to note that, as described by Google, each data point is divided by the total searches of the geography and time range it represents to compare relative popularity. These results, scaled on a range from 0 to 100 corresponds to an index, where 100 indicates the period where GMOs were the most discussed. Therefore, this unit method is based on proportionality and lacks to show the actual number of searches computed for a given term at a given time.
This limitation involved adapting others datasets to the same format, as there is no viable method to change an Index Base 100. 

The analysis of the public opinion then relied on correlation analysis, timeline analysis, and language analysis. First, correlations between public discussions and the level of implementation of genetically modified crops in the United-States were performed. From the US Department of Agriculture dataset, the general plantation of genetically modified crops was formatted in an Index Base 100, the same unit used in the Google Trend data. An Index Base 100 allows to see evolutions and accurately measure how the data changed over time, compared to its maximum value. Furthermore, a dataset in Index Base 100 can only be compared with another dataset using an Index Base 100. As for the economic analysis, only corn was used, as it is one of the most planted genetically-modified crops. Excel was used to convert the USDA dataset to an index, as it required multiple operations which Python inefficiently handled. This process created two different datasets, one for a national analysis, and the other for a state-analysis. States included in the analysis were all thirteen states included in the original USDA dataset, besides North Dakota, South Dakota and Kansas, as Google Trend did not provide reliable, sufficient data for these two states. Indeed, as Google Trend itself classified the data as "incomplete", those states were excluded from the analysis. 

For the national perspective, the dataset uses the index of the evolution of genetically modified crop in the United-States and its associated index of public discussion online, referred to as "public interactivity with the topic". Public interactivity defines how the general public interacted online with a topic. It corresponds to the frequency of searches on such topic through a given period and does not cover sentiment, or agreement with the topic. 
For the state's perspective, each state plantation index is associated with its own Google Trend index, therefore associating each state with a plantation level and a level of public interactivity. 
A total of eleven Pearson correlations were applied, one for the national perspective, and one for each ten states. Such process was realised through Python, using the scipy.stats.stats and pearsonr libraries. Pearson's correlation coefficients were then used to discuss the correlation levels between genetically modified production and public interactivity.

In parallel, to attempt to discuss causation, thorough research was conducted on key dates and events regarding genetic modification technology, including legislation and policy, civil marches and demonstrations, new scientific findings. These dates were then plotted on the general public interactivity graph to analyse which events might have triggered an intensive discussion online about GMO.

However, as Google Trend's public interactivity does not provide language analysis or sentiment analysis, Twitter API data was used to analyse those factors. 

Regarding visualisations, matplotlib graphs and bar charts were used, notably to compare all states' interactivities with GMOs and to plot the Pearson's correlation coefficients.

Twitter API

The use of the Twitter API allowed to perform a more concrete analysis of public opinion sentiments, as Google Trend only focused on public interactivity. The aims of each methods presented below was to quantitatively analyse which sentiments were associated to the topic of GMOs.

Around 200 tweets posted from the USA including the terms "GMO" or "genetically modified crops". Said tweets were collected using Twitter API search/tweets query, through Python. To access Twitter API resources through Python, the Colab file also authenticated account tokens and keys access. The collection method was parameterised by setting the search on the United-States, through the "country" parameters, and all Tweets collected were written in English. As queries only pulled 100 Tweets, the Colab file had to be run three times, with a week of interval. The results were then transcribed in a CSV file through Python, to be analysed. Using the natural language tool kit (NLTK) library on Python, natural language from the obtained text (collection of tweets) was processed. Indeed, collocations were run, and the twenty most common nouns, verbs and adjectives were identified. One limitation of the Twitter API is that the API did not allow a state-analysis, as the search query only accepted countries. Performing a state analysis would require an advance form of coding by entering all thirtheen latitudes and longitudes of each state mentionned above, tohugh the radius allowed by the API would not cover entirely the state territory, making such method unreliable. To prevent such issue and still have a state-approach to our research, we used a data frame published by Cambridge University which had previously compiled, over the course of two years, Tweets from each states. This research used classified Tweets as "positive", "neutral", or "negative" and also categorised their main concerns.This data was plotted on python after transposing it to a csv file using excel, namely the propprtion of negative, positive and neutral tweets in the 13 states proposed by the USDA as the most proficient GMO producers. 

Regarding the general sentiment analysis, for the national level, a polarity and subjectivity analysis was performed using the TextBlob library on Python on all Tweets compiled, than on individual Tweets using a for loop and the "sentence" parameter of the TextBlob library. Each polarity and subjectivity levels, given between -1 and 1 for polarity and 0 and 1 for subjectivity were added in a data frame. Such data frame was then used to perform diverse visualisations, notably histograms to see the repartition of polarity and subjectivity of Tweets, but also some boxplots using the seaborn library. Duplicates were excluded from the dataframe as they overly represented copy-pasted Tweets, which therefore should count as one. Tweets which were not assigned a polarity and subjectivity by TextBlob were also excluded, as no conclusions could be drawn from such Tweets. 
